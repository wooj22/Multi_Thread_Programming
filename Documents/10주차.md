# 10주차 C++ STL 스레드 프로그래밍 4
  
## std::atomic 고급 API 완벽 가이드

### atomic_flag - 가장 기본적인 atomic 타입
`atomic_flag`는 **유일하게 lock-free가 보장되는** atomic 타입이다. 불리언 플래그를 표현하며, 가장 저수준의 동기화 primitive이다.  
  
>>> lock-free란 “스레드 간 경합이 있더라도 커널 락이나 뮤텍스를 사용하지 않고, 오직 CPU의 원자적 명령어(atomic instruction)로만 동작한다”는 뜻이다.
>>> 즉, 어떤 스레드가 중단되더라도 다른 스레드가 반드시 계속 진행할 수 있다(progress guarantee).
>>> 대부분의 std::atomic<T> 타입은 “lock-free일 수도 있고 아닐 수도 있다” — 구현(플랫폼·컴파일러)에 따라 다르다. 예를 들어 std::atomic<int64_t>는 64비트 원자 연산을 지원하지 않는 32비트 CPU에서는 내부적으로 뮤텍스를 사용할 수 있다.  
 
#### 기본 사용법

```cpp
#include <atomic>
#include <thread>
#include <iostream>
#include <vector>

std::atomic_flag flag = ATOMIC_FLAG_INIT;  // 반드시 이렇게 초기화!

void worker(int id) {
    // test_and_set: 플래그를 true로 설정하고 이전 값 반환
    while (flag.test_and_set(std::memory_order_acquire)) {
        // 이미 설정되어 있으면 대기 (스핀)
    }
    
    // 임계 영역
    std::cout << "Worker " << id << " 작업 중...\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    
    // clear: 플래그를 false로 설정
    flag.clear(std::memory_order_release);
}

int main() {
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 5; ++i) {
        threads.emplace_back(worker, i);
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    return 0;
}
```

### C++20: test() 메서드
C++20부터는 플래그를 수정하지 않고 상태만 확인할 수 있다:

```cpp
#include <atomic>
#include <iostream>
#include <thread>

std::atomic_flag ready = ATOMIC_FLAG_INIT;

void producer() {
    std::cout << "데이터 준비 중...\n";
    std::this_thread::sleep_for(std::chrono::seconds(1));
    
    ready.test_and_set(std::memory_order_release);
    std::cout << "데이터 준비 완료!\n";
}

void consumer() {
    // C++20: test() - 상태만 읽기 (수정 안 함)
    while (!ready.test(std::memory_order_acquire)) {
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    
    std::cout << "데이터 소비 시작\n";
}

int main() {
    std::thread t1(producer);
    std::thread t2(consumer);
    
    t1.join();
    t2.join();
    
    return 0;
}
```
  

### C++20: wait(), notify_one(), notify_all()
C++20에서 모든 `std::atomic<T>`에 추가된 대기/통지 메커니즘이다.  

####  

```cpp
#include <atomic>
#include <thread>
#include <iostream>

std::atomic<int> value{0};

void waiter() {
    std::cout << "현재 값: " << value << ", 대기 시작...\n";
    
    // wait(old_value): value가 old_value와 다를 때까지 대기
    value.wait(0, std::memory_order_acquire);
    
    std::cout << "값이 변경됨! 새 값: " << value << "\n";
}

void notifier() {
    std::this_thread::sleep_for(std::chrono::seconds(1));
    
    value.store(42, std::memory_order_release);
    std::cout << "값 변경: 42\n";
    
    // 대기 중인 스레드 하나를 깨움
    value.notify_one();
}

int main() {
    std::thread t1(waiter);
    std::thread t2(notifier);
    
    t1.join();
    t2.join();
    
    return 0;
}
```

#### 실용 예제: 세마포어 구현

```cpp
// 필요한 헤더 파일들을 포함합니다.
#include <atomic>   // std::atomic, 메모리 순서 관련 (C++20의 wait/notify 포함)
#include <thread>   // std::thread, std::this_thread
#include <vector>   // std::vector (스레드들을 관리하기 위해)
#include <iostream> // std::cout (콘솔 출력용)

/**
 * @brief C++20 std::atomic을 사용한 세마포어 클래스
 * * 세마포어는 지정된 개수(permit)만큼의 스레드만 
 * 특정 코드 영역(임계 영역)에 동시 접근하도록 제어하는 동기화 도구입니다.
 */
class Semaphore {
private:
    // 사용 가능한 리소스(permit)의 개수를 나타내는 atomic 정수
    // atomic을 사용하여 여러 스레드에서 동시에 접근해도 안전합니다.
    std::atomic<int> count;

public:
    /**
     * @brief 세마포어 생성자
     * @param initial_count 처음에 사용 가능한 리소스의 개수
     */
    explicit Semaphore(int initial_count) : count(initial_count) {}

    /**
     * @brief 리소스를 획득합니다 (P 연산).
     * * 리소스가 남아있으면 count를 1 감소시키고 즉시 반환합니다.
     * 리소스가 없으면(count <= 0) 리소스가 생길 때까지(다른 스레드가 release() 할 때까지)
     * 이 스레드를 대기(block)시킵니다.
     */
    void acquire() {
        // 현재 count 값을 읽어옵니다.
        // memory_order_acquire: 이 load 이후의 모든 메모리 읽기/쓰기는
        //                      다른 스레드에서 release한 작업 이후에 발생하도록 보장합니다.
        int old_count = count.load(std::memory_order_acquire);
        
        // 리소스를 성공적으로 획득할 때까지 반복합니다.
        while (true) {
            
            // --- 1. 리소스가 없는지 확인하고 대기 ---
            // 현재 카운트가 0 이하면 리소스가 없다는 의미이므로 대기합니다.
            while (old_count <= 0) {
                // count.wait(): count의 값이 old_count와 '같다면' 스레드를 대기시킵니다.
                // 만약 wait() 호출 직전에 다른 스레드가 release()해서 count 값이
                // old_count와 달라졌다면, 스레드는 대기하지 않고 즉시 반환됩니다. (Spurious wakeup 방지)
                // 이는 C++20부터 사용 가능한 기능입니다.
                count.wait(old_count, std::memory_order_acquire);
                
                // wait()에서 깨어났으므로 (다른 스레드가 notify_one()을 호출했거나, 
                // 스퓨리어스 웨이크업이 발생했으므로) count 값을 다시 읽습니다.
                old_count = count.load(std::memory_order_acquire);
            }
            
            // --- 2. 리소스 획득 시도 ---
            // 이 시점에서는 old_count > 0 입니다. (즉, 리소스가 *있었음*)
            // 이제 이 리소스를 '내가' 획득하기 위해 count 값을 1 감소시키려고 시도합니다.
            
            // compare_exchange_weak (CAS, 비교-교환 연산):
            // 1. 현재 'count'의 값과 'old_count'를 비교합니다.
            // 2. [성공] 만약 두 값이 같다면 (즉, 내가 값을 읽은 후 아무도 count를 변경하지 않음):
            //    'count'의 값을 'old_count - 1'로 *원자적으로* 변경하고 true를 반환합니다.
            // 3. [실패] 만약 두 값이 다르다면 (즉, 그 사이에 다른 스레드가 acquire/release를 함):
            //    'count'의 값을 변경하지 않고, 'old_count' 변수의 값을 
            //    *현재의 'count' 값으로 덮어쓴 후* false를 반환합니다.
            //
            // 'weak' 버전은 루프 안에서 사용할 때 더 효율적일 수 있습니다. 
            // (성공해야 할 때도 스퓨리어스하게 실패할 수 있지만, 어차피 루프가 다시 돕니다.)
            if (count.compare_exchange_weak(old_count, old_count - 1,
                                            std::memory_order_acquire, // 성공 시 메모리 순서
                                            std::memory_order_acquire)) // 실패 시 메모리 순서
            {
                // CAS 성공! 리소스를 획득했으므로 함수를 종료합니다.
                return;
            }
            // CAS 실패:
            // old_count 값은 'compare_exchange_weak'에 의해 현재 count 값으로 
            // 자동 업데이트되었습니다.
            // while(true) 루프의 처음으로 돌아가서 다시 시도합니다.
            // (만약 업데이트된 old_count가 0 이하라면, 다시 안쪽 while 루프로 들어가 wait() 합니다.)
        }
    }

    /**
     * @brief 리소스를 반납합니다 (V 연산).
     * * count를 1 증가시키고, 혹시 대기 중인 스레드가 있다면 하나를 깨웁니다.
     */
    void release() {
        // count 값을 원자적으로 1 증가시킵니다.
        // memory_order_release: 이 fetch_add '이전'의 모든 메모리 읽기/쓰기 작업이
        //                      이 연산 이후에 acquire하는 다른 스레드에게 보이도록 보장합니다.
        count.fetch_add(1, std::memory_order_release);
        
        // count.wait()에서 대기 중인 스레드가 있을 수 있으므로,
        // 그중 하나를 깨워서 리소스 획득을 다시 시도하도록 신호를 보냅니다.
        count.notify_one();
    }
};

// --- 세마포어 사용 예제 ---

// 전역 세마포어 객체를 생성합니다.
// 초기 카운트를 3으로 설정 => 최대 3개의 스레드만 동시에 "작업"을 수행할 수 있습니다.
Semaphore sem(3);

/**
 * @brief 각 스레드가 실행할 작업 함수
 * @param id 스레드를 식별하기 위한 ID
 */
void worker(int id) {
    // 1. 리소스 획득 시도 (대기)
    std::cout << "Thread " << id << " 대기 중...\n";
    sem.acquire(); // 세마포어 카운트가 3이므로, 3개 스레드까지만 여기를 통과합니다.
                   // 4번째 스레드부터는 여기서 대기(block)합니다.
    
    // --- 임계 영역 (Critical Section) 시작 ---
    // 이 영역은 동시에 최대 3개의 스레드만 실행할 수 있습니다.
    std::cout << "Thread " << id << " 작업 시작\n";
    
    // 1초 동안 작업을 시뮬레이션합니다.
    std::this_thread::sleep_for(std::chrono::seconds(1));
    
    std::cout << "Thread " << id << " 작업 완료\n";
    // --- 임계 영역 (Critical Section) 끝 ---

    // 2. 리소스 반납
    sem.release(); // 작업을 마쳤으므로 리소스를 반납합니다.
                   // 이 호출로 인해 대기 중이던 다른 스레드 하나가 깨어나 
                   // acquire()에 성공하고 작업을 시작할 수 있게 됩니다.
}

int main() {
    // 생성된 스레드 객체들을 관리하기 위한 벡터
    std::vector<std::thread> threads;
    
    // 총 10개의 스레드를 생성합니다.
    for (int i = 0; i < 10; ++i) {
        // worker 함수를 실행하는 새 스레드를 생성하고 벡터에 추가합니다.
        // 'i'가 worker 함수의 'id' 인자로 전달됩니다.
        threads.emplace_back(worker, i);
        
        // 스레드 생성 사이에 약간의 딜레이를 주어 
        // 스레드들이 순차적으로 시작되는 것을 관찰하기 용이하게 합니다.
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
    
    // main 스레드가 모든 worker 스레드가 끝날 때까지 기다립니다.
    for (auto& t : threads) {
        t.join(); // 해당 스레드가 종료될 때까지 대기
    }
    
    return 0;
}
```

### wait() vs std::mutex  
`std::atomic::wait()`는 내부적으로 리눅스에서는 `futex`(fast userspace mutex)를 사용해 구현되어 있어, 커널 진입이 적고 매우 가볍게 동작한다. 하지만 그렇다고 해서 `std::mutex`를 모두 `atomic::wait()` 기반으로 바꾸는 것이 좋은 선택은 아니다. 
  
#### 1. **기본 동작 방식의 차이**

* **`std::mutex`**

  * 임계 구역(critical section)을 보호하기 위한 **상호 배제(mutual exclusion)** 기능을 제공한다.
  * 한 스레드만 락을 획득할 수 있으며, 다른 스레드는 자동으로 블록된다.
  * 내부적으로도 `futex`를 사용할 수 있지만, 락의 상태 관리·소유권·재진입 가능성 등을 함께 처리한다.

* **`std::atomic::wait()` / `notify_one()`**

  * 단순히 **값 변화에 대해 대기(wait)** 하는 기능만 제공한다.
  * “조건이 만족될 때까지 잠들고, 값이 바뀌면 깨어난다”는 형태다.
  * 락 소유권 개념이 없고, 데이터 경쟁을 방지하지 않는다.
  * 즉, `atomic::wait()`은 **동기화 원자적 조건 대기**를 위한 것이고, **상호 배제**를 위한 것이 아니다.

#### 2. **성능 차이**

* 단순 대기/알림 시나리오(예: 생산자–소비자 큐, 스핀락 대체)에서는 `atomic::wait()`이 `mutex + condition_variable` 조합보다 빠르다.

  * 커널 호출 수가 줄고, 사용자 공간에서 대부분 처리된다.
* 하지만 **락을 통한 자원 보호**가 필요한 경우에는 `std::mutex`가 더 안전하고, 유지보수하기 쉽다.
* `atomic::wait()`는 락이 아니라서, 메모리 일관성 확보나 예외 처리 중 락 해제 같은 안전 장치가 없다.


#### 3. **적합한 사용 시나리오**

| 상황                                   | 권장 도구                                       | 이유                     |
| ------------------------------------ | ------------------------------------------- | ---------------------- |
| 공유 데이터 접근 보호                         | `std::mutex`                                | 상호 배제, RAII, 예외 안전성 보장 |
| 상태 변화 신호 대기 (예: flag 변경 시 대기)        | `std::atomic::wait`                         | 락 오버헤드 없이 빠른 동기화 가능    |
| 다수 스레드의 조건 대기 (예: producer-consumer) | `std::condition_variable` 또는 `atomic::wait` | 후자는 간단한 경우에 적합         |
| 높은 빈도의 빠른 wake-up/wait 루프            | `std::atomic::wait`                         | futex 기반이라 매우 효율적      |


#### 4. **결론**

* `std::atomic::wait()`는 **조건 동기화(값 변경 알림)** 용이지 **상호 배제(lock)** 용이 아니다.
* `std::mutex`는 복잡한 자원 보호, 예외 안전성, 명확한 락 스코프 관리에 적합하다.
* 따라서, 단순히 “성능이 더 좋아 보인다”는 이유로 `mutex`를 `atomic::wait()`로 교체하면 데이터 레이스나 미묘한 버그를 유발할 수 있다.
* `atomic::wait()`는 락 프리(futex 기반) 동기화 패턴을 직접 설계할 때만 사용하는 것이 좋다.

  
### compare_exchange_weak() vs compare_exchange_strong()

```cpp
#include <atomic>
#include <iostream>

/*
compare_exchange_strong:
- 예상 값과 실제 값이 같으면 반드시 교환 성공
- Spurious failure (가짜 실패) 없음
- 단일 시도에 적합

compare_exchange_weak:
- 예상 값과 실제 값이 같아도 실패할 수 있음 (spurious failure)
- 하드웨어 최적화 가능 (일부 아키텍처에서 더 빠름)
- 루프 안에서 사용에 적합
*/

std::atomic<int> value{100};

void demonstrate_strong() {
    std::cout << "=== compare_exchange_strong ===\n";
    
    int expected = 100;
    bool success = value.compare_exchange_strong(expected, 200);
    
    if (success) {
        std::cout << "성공: 100 -> 200\n";
    } else {
        std::cout << "실패. 실제 값: " << expected << "\n";
    }
    
    // 단일 시도로도 신뢰 가능
}

void demonstrate_weak() {
    std::cout << "\n=== compare_exchange_weak (루프 필요) ===\n";
    
    value.store(100);
    int expected = 100;
    
    // weak는 루프에서 사용해야 함
    while (!value.compare_exchange_weak(expected, 300,
                                       std::memory_order_release,
                                       std::memory_order_relaxed)) {
        std::cout << "재시도... (expected는 자동 갱신됨: " << expected << ")\n";
        expected = 100;  // 다시 설정
    }
    
    std::cout << "최종 성공: " << value << "\n";
}

int main() {
    demonstrate_strong();
    demonstrate_weak();
    
    return 0;
}
```
   
compare_exchange_weak는 **(1) 약한 CAS는 스푸리어스 실패가 있을 수 있다**, **(2) 그래서 하드웨어에 더 직접 맞춰 최적화될 수 있다**, **(3) 그 때문에 보통 루프 안에서 쓰도록 설계되었다**이다. 각각을 조금 더 파고들어 설명한다.

#### “예상 값과 같아도 실패할 수 있음”의 의미
`compare_exchange_weak(expected, desired)`는 내부적으로 **읽기→비교→교체**를 한 번의 원자 동작으로 시도하다가, **비교가 참이어도 실패**(false 반환)할 수 있다. 이를 **스푸리어스 실패(spurious failure)**라고 부른다.

* 실패해도 **메모리는 변경되지 않는다**.
* 실패 시 `expected`는 **메모리에 실제로 있던 값**으로 갱신된다.
* 그래서 보통은 다음처럼 **재시도 루프**가 전제다.

```cpp
std::atomic<int> a{0};
int expected = 0;
int desired  = 42;

while (!a.compare_exchange_weak(expected, desired)) {
    // 여기로 왔다는 건 두 경우뿐이다:
    // 1) 누군가 값(a)을 바꿔서 비교 자체가 틀림 → expected에 실제 값이 들어옴
    // 2) 비교는 맞았지만 스푸리어스 실패
    // 보통은 expected를 기반으로 다시 desired를 계산하거나, 그대로 재시도한다
}
```

왜 이런 실패가 생기나?
많은 아키텍처는 CAS를 **LL/SC(Load-Linked/Store-Conditional)** 로 구현한다. SC는 “그 사이에 누가 건드렸나” 같은 미세한 조건 때문에 **성공이 아주 보수적으로 판정**된다. 그 결과 간헐적인 실패(스푸리어스)가 발생할 수 있다. `weak`은 이 특성을 그대로 노출한다.

#### “하드웨어 최적화 가능”의 의미
* `weak`은 “가끔 실패해도 되니 **그냥 한 번 시도만** 해줘”라는 의미에 가깝다.
* 반면 `compare_exchange_strong`은 **스푸리어스 실패가 ‘거의 없다’**는 계약을 주고, 구현체가 내부에서 **조금 더 비싼 재시도**를 넣을 여지가 있다.
* 그래서 **ARM, POWER**처럼 LL/SC 기반 CPU에선 `weak`이 **한 번 시도 후 바로 리턴**하며 호출 측 루프에 재시도를 맡기므로 더 효율적일 수 있다.
* **x86(x64)** 처럼 진짜 CAS(LOCK CMPXCHG)를 갖는 아키텍처에서는 `weak`과 `strong`의 성능/동작 차이가 **사실상 없는 경우가 많다**.

정리하면, `weak`은 **플랫폼이 허락하면 더 얇고 빠른 경로**를 탈 수 있도록 API 수준에서 공간을 준 것이다.

#### “루프 안에서 사용에 적합”의 의미
스푸리어스 실패가 가능하니, **루프로 감싸 재시도**하는 패턴이 기본이다. 루프 외 단발성으로 쓰면 실패를 실제 실패로 오해할 수 있다.

```cpp
// push 예시(단순화)
struct Node { int v; Node* next; };
std::atomic<Node*> head{nullptr};

void push(Node* n) {
    Node* old = head.load(std::memory_order_relaxed);
    do {
        n->next = old;
        // 실패 시 old가 실제 head로 갱신되므로 다음 시도에서 다시 연결
    } while (!head.compare_exchange_weak(
                 old, n,
                 std::memory_order_release,   // 성공 시
                 std::memory_order_relaxed)); // 실패 시
}
```

* `old`는 “기대 값”이자 **항상 최신 헤드로 갱신**되므로 다음 시도가 자연스럽게 이어진다.
* 루프 구조 덕분에 **경합이 심하거나 스푸리어스 실패가 잦아도** 올바르게 진전된다.
* 경합이 심하면 **지수 백오프** 등을 섞어 낭비를 줄일 수 있다.

```cpp
for (int backoff = 1; !cas_ok; backoff = std::min(backoff*2, 1<<10)) {
    // compare_exchange_weak 재시도...
    for (int i = 0; i < backoff; ++i) { __builtin_ia32_pause(); } // x86이라면
}
```

#### `weak` vs `strong`를 고를 때의 가이드
* **루프 내 재시도 전제**라면 `weak`을 선호한다.
  구현체가 불필요한 내부 재시도를 하지 않으므로 LL/SC 아키텍처에서 효율적일 가능성이 높다.
* **단발성 시도**나 **재시도 비용을 호출 측에서 원치 않을 때**는 `strong`을 고려한다.
  다만 고성능 락프리 구조에서는 대부분 루프이므로 `weak`을 쓰는 경우가 많다.

#### 메모리 오더와 함께 쓸 때의 주의점
* 성공/실패 두 개의 오더를 받는 오버로드가 있다. **실패 오더는 `release` 또는 `acq_rel`일 수 없다**는 제약이 있다. 보통 실패 측은 `relaxed`로 둔다.
* RMW(CAS 포함)에서 **상태 전달**이 필요하면 성공 측에 `acq_rel` 혹은 `release`/`acquire` 조합을 올바르게 설정한다.
* 기본은 `seq_cst`라서 정확성은 맞지만, 뜨거운 경합 구간에서는 `acq_rel/relaxed`로 미세 조정해 성능을 끌어올린다.

#### 흔한 함정과 팁
* **스푸리어스 실패를 진짜 경쟁 실패로 착각**하지 말아야 한다. `weak`은 실패가 “정상”일 수 있으므로 반드시 루프 재시도 구조를 쓴다.
* CAS 기반 알고리즘은 **ABA 문제**가 생길 수 있다. 필요하면 세대 카운터(tag)나 `atomic<std::uintptr_t>`로 상위 비트에 **version**을 얹어 해결한다.
* `expected`가 바뀐다는 점을 잊지 말아야 한다. 실패 시 곧바로 같은 `desired`로 재시도하려면 `expected`를 새 값으로 유지한 채 돌려야 한다.

#### 실전 사용 예제: Lock-Free 큐

```cpp
// 필요한 헤더 파일들을 포함합니다.
#include <atomic>   // std::atomic, 원자적 연산 및 메모리 순서(memory order)를 위해
#include <memory>   // std::shared_ptr, std::make_shared (데이터의 생명주기 관리)
#include <optional> // std::optional (dequeue가 비어있을 경우를 표현하기 위해)
#include <iostream> // main 함수 예제에서 출력을 위해

/**
 * @brief 템플릿 기반의 락프리(Lock-Free) 큐
 * * 연결 리스트(linked list) 기반이며, 락(mutex) 대신
 * atomic 연산을 사용하여 스레드 안전성을 보장합니다.
 * "dummy" (또는 "sentinel") 노드를 사용하여 구현을 단순화합니다.
 */
template<typename T>
class LockFreeQueue {
private:
    /**
     * @brief 큐의 각 요소를 나타내는 노드 구조체
     */
    struct Node {
        // 실제 데이터. std::shared_ptr를 사용해 데이터의 생명주기를 관리합니다.
        // 노드가 삭제되더라도 데이터가 필요한 곳이 있다면 안전하게 참조할 수 있습니다.
        // (이 특정 구현에서는 std::unique_ptr도 가능했을 수 있습니다.)
        std::shared_ptr<T> data;
        
        // 다음 노드를 가리키는 포인터.
        // 여러 스레드가 동시에 접근(읽기/쓰기)할 수 있으므로 atomic이어야 합니다.
        std::atomic<Node*> next;
        
        // 생성자: next 포인터를 nullptr로 초기화합니다.
        Node() : next(nullptr) {}
    };
    
    // 큐의 맨 앞(데이터가 나가는 곳)을 가리키는 포인터.
    // 'head'는 항상 *첫 번째 데이터가 담긴 노드의 이전 노드* (즉, dummy 노드)를 가리킵니다.
    std::atomic<Node*> head;
    
    // 큐의 맨 뒤(데이터가 들어오는 곳)를 가리키는 포인터.
    std::atomic<Node*> tail;

public:
    /**
     * @brief 생성자
     * 큐를 초기화할 때, 비어있는 상태를 쉽게 처리하기 위해
     * 'dummy(더미)' 노드를 하나 생성하여 head와 tail이 모두 이 노드를 가리키게 합니다.
     * * 초기 상태: [dummy] -> nullptr
     * ^        ^
     * head     tail
     */
    LockFreeQueue() {
        Node* dummy = new Node(); // 데이터가 없는 더미 노드 생성
        head.store(dummy);
        tail.store(dummy);
    }
    
    /**
     * @brief 소멸자
     * 큐가 파괴될 때 모든 노드를 순회하며 메모리를 해제합니다.
     * *주의: 이 소멸자 자체는 스레드에 안전하지 않습니다.*
     * *즉, 큐가 소멸되는 시점에는 다른 스레드가 이 큐를 사용하고 있지 않아야 합니다.*
     */
    ~LockFreeQueue() {
        while (Node* old_head = head.load()) {
            head.store(old_head->next); // head를 다음 노드로 이동
            delete old_head;            // 이전 head 노드 삭제
        }
    }

    /**
     * @brief 큐의 맨 뒤에 데이터를 추가합니다 (Enqueue).
     * @param value 큐에 추가할 값
     */
    void enqueue(T value) {
        // 1. 데이터를 shared_ptr로 감싸고 새 노드를 생성합니다.
        auto new_data = std::make_shared<T>(std::move(value));
        Node* new_node = new Node();
        new_node->data = new_data;
        
        // 2. CAS(Compare-And-Swap) 루프를 시작합니다.
        //    성공할 때까지 계속 시도합니다.
        Node* old_tail = tail.load(); // 현재 tail 값을 읽습니다.
        
        while (true) {
            Node* tail_next = old_tail->next.load(); // tail이 가리키는 노드의 'next'를 읽습니다.
            
            // 3. 'old_tail'이 정말로 마지막 노드인지 확인합니다.
            
            // [CASE 1: 'old_tail'이 마지막 노드인 경우 (정상)]
            if (tail_next == nullptr) {
                // 'old_tail->next'를 nullptr에서 new_node로 바꾸려고 시도합니다.
                // compare_exchange_weak: 루프 안에서 사용되며, 'strong'보다 성능상 이점이 있을 수 있습니다.
                //                        (때때로 '가짜 실패'를 반환할 수 있지만 어차피 루프가 다시 돕니다.)
                if (old_tail->next.compare_exchange_weak(
                        tail_next, // (기대값) tail_next가 여전히 nullptr일 것이라 기대
                        new_node,  // (새 값) new_node로 변경
                        std::memory_order_release, // 이 쓰기 연산 이전의 모든 쓰기를 다른 스레드에 보이도록 함
                        std::memory_order_relaxed)) // 실패 시에는 특별한 순서 보장 불필요
                {
                    // 4. 노드 연결 성공!
                    
                    // 5. 'tail' 포인터도 'new_node'로 갱신을 "시도"합니다.
                    //    이 작업은 실패해도 괜찮습니다. (다른 스레드가 이미 갱신했을 수 있음)
                    //    큐에 노드가 추가된 것은 이미 'next' 포인터 연결로 보장되었습니다.
                    //    'tail'이 뒤쳐지는 것은 'dequeue'나 다른 'enqueue'에서 처리해 줍니다.
                    tail.compare_exchange_strong(old_tail, new_node,
                                                 std::memory_order_release,
                                                 std::memory_order_relaxed);
                    return; // Enqueue 성공, 함수 종료
                }
                // (CAS 실패: 'tail_next'가 그새 nullptr이 아니게 됨.
                //  'old_tail'은 CAS에 의해 현재 'tail' 값으로 갱신되었거나,
                //  우리가 직접 'tail.load()'로 갱신해야 합니다.
                //  여기서는 'weak'가 실패했으므로 'tail_next' 값이 바뀌었을 수 있습니다.
                //  루프가 다시 돌면서 'old_tail'을 다시 읽거나 'CASE 2'로 빠집니다.)
                
            } 
            // [CASE 2: 'old_tail'이 마지막 노드가 아닌 경우]
            // (즉, 'tail_next'가 nullptr이 아님)
            // 'tail' 포인터가 뒤쳐져(lagging) 있습니다.
            // 다른 스레드가 노드를 추가했지만 'tail' 포인터는 아직 갱신하지 못한 상태입니다.
            else {
                // 'tail' 포인터를 실제 마지막 노드('tail_next')로 갱신하도록 "도와줍니다".
                tail.compare_exchange_weak(old_tail, tail_next,
                                           std::memory_order_release,
                                           std::memory_order_relaxed);
            }
            
            // CAS가 실패했거나(CASE 1), tail을 갱신(CASE 2)했으므로,
            // 현재 'tail' 값을 다시 읽고 루프를 처음부터 다시 시작합니다.
            old_tail = tail.load();
        }
    }

    /**
     * @brief 큐의 맨 앞에서 데이터를 빼옵니다 (Dequeue).
     * @return 데이터가 있으면 std::optional<T>에 담아 반환하고,
     * 큐가 비어있으면 std::nullopt를 반환합니다.
     */
    std::optional<T> dequeue() {
        // CAS 루프 시작
        while (true) {
            // 1. 현재 head, tail, 그리고 head의 다음 노드(첫 번째 실제 데이터 노드)를 읽습니다.
            //    memory_order_acquire: enqueue의 'release'와 동기화하여,
            //                          다른 스레드가 쓴 데이터를 올바르게 읽어옵니다.
            Node* old_head = head.load(std::memory_order_acquire);
            Node* old_tail = tail.load(std::memory_order_acquire);
            Node* next = old_head->next.load(std::memory_order_acquire);
            
            // 2. 읽어온 'head'가 그 사이에 다른 스레드에 의해 변경되지 않았는지 확인합니다.
            //    (이중 확인)
            if (old_head == head.load(std::memory_order_acquire)) {
                
                // [CASE 1: head와 tail이 같은 노드를 가리킴]
                if (old_head == old_tail) {
                    
                    // [CASE 1a: 큐가 비어있음]
                    if (next == nullptr) {
                        // head와 tail이 같고, next가 null이면 큐는 비어있습니다.
                        // [dummy] -> nullptr
                        //  ^
                        // head, tail
                        return std::nullopt;
                    }
                    
                    // [CASE 1b: tail이 뒤쳐져 있음 (Lagging Tail)]
                    // head와 tail은 같지만, next가 null이 아닙니다.
                    // enqueue에서 'tail' 갱신을 아직 못한 상태입니다.
                    // [dummy] -> [data1] -> nullptr
                    //  ^           ^
                    // head,tail   (real tail)
                    // 'tail'을 'next'로 갱신하도록 "도와줍니다".
                    tail.compare_exchange_weak(old_tail, next,
                                               std::memory_order_release,
                                               std::memory_order_relaxed);
                    // (그리고 루프 재시도)
                }
                
                // [CASE 2: head와 tail이 다름 (큐에 데이터가 1개 이상 있음)]
                else {
                    // 'next'가 null인 경우는 일시적인 불일치 상태일 수 있습니다.
                    // (예: 다른 dequeue가 'head'를 막 바꾸려는 순간)
                    // 안전하게 재시도합니다.
                    if (next == nullptr) {
                        continue;
                    }

                    // 3. 'next' 노드(첫 번째 데이터 노드)에서 데이터를 "복사"합니다.
                    T result = *next->data; 
                    
                    // 4. 'head' 포인터를 'old_head'(현재 더미 노드)에서 
                    //    'next'(첫 번째 데이터 노드)로 이동시킵니다.
                    if (head.compare_exchange_weak(old_head, next,
                                                   std::memory_order_release,
                                                   std::memory_order_relaxed)) {
                        
                        // 5. CAS 성공! head가 성공적으로 이동했습니다.
                        // 'old_head'(이전 더미 노드)는 이제 큐에서 완전히 분리되었으므로
                        // 안전하게 삭제할 수 있습니다.
                        delete old_head;
                        
                        // 'next' 노드가 *새로운 더미 노드*가 됩니다.
                        // (이 노드의 'data'는 이미 'result'로 복사되었으므로 더 이상 필요하지 않습니다.)
                        
                        // 6. 복사해 둔 데이터를 반환합니다.
                        return result;
                    }
                    // (CAS 실패: 다른 스레드가 먼저 dequeue에 성공함. 루프 재시도)
                }
            }
            // (head가 중간에 변경되었음. 루프 재시도)
        }
    }
};

// --- 예제 main 함수 ---

int main() {
    LockFreeQueue<int> queue; // 락프리 큐 생성
    
    // 생산자 스레드: 0부터 99까지 100개의 숫자를 큐에 넣습니다.
    std::thread producer([&]() {
        for (int i = 0; i < 100; ++i) {
            queue.enqueue(i);
            std::cout << "Enqueued: " << i << "\n";
            // (출력이 섞일 수 있으므로 실제 락프리 코드에서는 cout을 조심해야 함)
        }
    });
    
    // 소비자 스레드: 큐에서 100개의 숫자를 꺼냅니다.
    std::thread consumer([&]() {
        int count = 0;
        while (count < 100) {
            // dequeue는 큐가 비어있으면 nullopt를 반환합니다.
            auto value = queue.dequeue();
            if (value) { // 값이 성공적으로 꺼내졌다면
                std::cout << "Dequeued: " << *value << "\n";
                ++count;
            }
            // (값이 없다면 큐가 비어있는 것이므로, 루프를 다시 돌며 계속 시도합니다. - "Spinning")
        }
    });
    
    // 두 스레드가 모두 종료될 때까지 대기합니다.
    producer.join();
    consumer.join();
    
    return 0;
}
```
  

### fetch_* 계열 함수들

#### 산술 연산

```cpp
#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

void demonstrate_fetch_operations() {
    std::atomic<int> value{100};
    
    std::cout << "=== 산술 연산 ===\n";
    std::cout << "초기값: " << value << "\n";
    
    // fetch_add: 더하고 이전 값 반환
    int prev = value.fetch_add(50, std::memory_order_relaxed);
    std::cout << "fetch_add(50) - 이전: " << prev << ", 현재: " << value << "\n";
    
    // fetch_sub: 빼고 이전 값 반환
    prev = value.fetch_sub(30, std::memory_order_relaxed);
    std::cout << "fetch_sub(30) - 이전: " << prev << ", 현재: " << value << "\n";
    
    // 연산자 오버로딩 버전 (반환 값이 다름!)
    value += 20;  // 새 값 반환
    std::cout << "operator+=(20) - 현재: " << value << "\n";
    
    value -= 10;
    std::cout << "operator-=(10) - 현재: " << value << "\n";
}

void demonstrate_pointer_arithmetic() {
    std::cout << "\n=== 포인터 산술 ===\n";
    
    int array[10] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};
    std::atomic<int*> ptr{array};
    
    std::cout << "초기 값: " << *ptr << "\n";
    
    // fetch_add: 포인터를 n만큼 전진
    int* old_ptr = ptr.fetch_add(3, std::memory_order_relaxed);
    std::cout << "fetch_add(3) - 이전: " << *old_ptr 
              << ", 현재: " << *ptr << "\n";
    
    // fetch_sub: 포인터를 n만큼 후진
    old_ptr = ptr.fetch_sub(1, std::memory_order_relaxed);
    std::cout << "fetch_sub(1) - 이전: " << *old_ptr 
              << ", 현재: " << *ptr << "\n";
}

int main() {
    demonstrate_fetch_operations();
    demonstrate_pointer_arithmetic();
    
    return 0;
}
```

#### 비트 연산

```cpp
#include <atomic>
#include <iostream>
#include <bitset>

void demonstrate_bitwise_operations() {
    std::atomic<unsigned int> flags{0b00001111};
    
    auto print_flags = [](const std::string& msg, unsigned int val) {
        std::cout << msg << std::bitset<8>(val) << " (" << val << ")\n";
    };
    
    print_flags("초기값: ", flags.load());
    
    // fetch_or: OR 연산 후 이전 값 반환
    unsigned int prev = flags.fetch_or(0b11110000, std::memory_order_relaxed);
    print_flags("fetch_or(11110000) - 이전: ", prev);
    print_flags("                      현재: ", flags.load());
    
    // fetch_and: AND 연산 후 이전 값 반환
    prev = flags.fetch_and(0b10101010, std::memory_order_relaxed);
    print_flags("fetch_and(10101010) - 이전: ", prev);
    print_flags("                       현재: ", flags.load());
    
    // fetch_xor: XOR 연산 후 이전 값 반환
    prev = flags.fetch_xor(0b11111111, std::memory_order_relaxed);
    print_flags("fetch_xor(11111111) - 이전: ", prev);
    print_flags("                       현재: ", flags.load());
}

// 실용 예제: 비트 플래그 관리
class FeatureFlags {
private:
    enum : unsigned int {
        FEATURE_A = 1 << 0,  // 0b0001
        FEATURE_B = 1 << 1,  // 0b0010
        FEATURE_C = 1 << 2,  // 0b0100
        FEATURE_D = 1 << 3   // 0b1000
    };
    
    std::atomic<unsigned int> flags{0};

public:
    void enable(unsigned int feature) {
        unsigned int old = flags.fetch_or(feature, std::memory_order_relaxed);
        std::cout << "Feature enabled. Old: " << std::bitset<4>(old)
                  << ", New: " << std::bitset<4>(flags.load()) << "\n";
    }
    
    void disable(unsigned int feature) {
        unsigned int old = flags.fetch_and(~feature, std::memory_order_relaxed);
        std::cout << "Feature disabled. Old: " << std::bitset<4>(old)
                  << ", New: " << std::bitset<4>(flags.load()) << "\n";
    }
    
    void toggle(unsigned int feature) {
        unsigned int old = flags.fetch_xor(feature, std::memory_order_relaxed);
        std::cout << "Feature toggled. Old: " << std::bitset<4>(old)
                  << ", New: " << std::bitset<4>(flags.load()) << "\n";
    }
    
    bool is_enabled(unsigned int feature) const {
        return (flags.load(std::memory_order_relaxed) & feature) != 0;
    }
};

int main() {
    demonstrate_bitwise_operations();
    
    std::cout << "\n=== Feature Flags 예제 ===\n";
    FeatureFlags features;
    
    features.enable(1 << 0);   // FEATURE_A
    features.enable(1 << 2);   // FEATURE_C
    features.toggle(1 << 0);   // FEATURE_A 토글
    features.disable(1 << 2);  // FEATURE_C
    
    return 0;
}
```

#### C++20: fetch_max() / fetch_min()

```cpp
#include <atomic>
#include <thread>
#include <vector>
#include <iostream>
#include <random>

// 여러 스레드에서 최댓값/최솟값 추적
class MinMaxTracker {
private:
    std::atomic<int> min_value{INT_MAX};
    std::atomic<int> max_value{INT_MIN};

public:
    void update(int value) {
        // C++20: fetch_min - 더 작은 값으로 갱신
        int old_min = min_value.fetch_min(value, std::memory_order_relaxed);
        
        // C++20: fetch_max - 더 큰 값으로 갱신
        int old_max = max_value.fetch_max(value, std::memory_order_relaxed);
        
        if (value < old_min || value > old_max) {
            std::cout << "Thread " << std::this_thread::get_id() 
                      << " - 값 갱신: " << value << "\n";
        }
    }
    
    void print() const {
        std::cout << "Min: " << min_value.load() 
                  << ", Max: " << max_value.load() << "\n";
    }
};

// fetch_min/max를 사용한 대안 구현 (C++20 이전)
void update_min_legacy(std::atomic<int>& atomic_min, int value) {
    int old_min = atomic_min.load(std::memory_order_relaxed);
    
    while (value < old_min &&
           !atomic_min.compare_exchange_weak(old_min, value,
                                            std::memory_order_relaxed,
                                            std::memory_order_relaxed)) {
        // old_min이 자동으로 갱신됨
    }
}

int main() {
    MinMaxTracker tracker;
    std::vector<std::thread> threads;
    
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<> dis(1, 1000);
    
    for (int i = 0; i < 10; ++i) {
        threads.emplace_back([&, i]() {
            for (int j = 0; j < 10; ++j) {
                int value = dis(gen);
                tracker.update(value);
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
            }
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    std::cout << "\n최종 결과:\n";
    tracker.print();
    
    return 0;
}
```
  

### 특수 목적 함수들

#### is_always_lock_free (C++17)

```cpp
#include <atomic>
#include <iostream>

template<typename T>
void check_lock_free() {
    std::cout << "Type: " << typeid(T).name() << "\n";
    
    // 컴파일 타임 상수
    std::cout << "  is_always_lock_free: " 
              << std::atomic<T>::is_always_lock_free << "\n";
    
    // 런타임 체크
    std::atomic<T> a;
    std::cout << "  is_lock_free(): " << a.is_lock_free() << "\n";
    
    std::cout << "\n";
}

struct SmallStruct {
    char data[4];
};

struct LargeStruct {
    char data[1024];
};

int main() {
    std::cout << std::boolalpha;
    
    check_lock_free<bool>();
    check_lock_free<char>();
    check_lock_free<int>();
    check_lock_free<long long>();
    check_lock_free<float>();
    check_lock_free<double>();
    check_lock_free<void*>();
    check_lock_free<SmallStruct>();
    check_lock_free<LargeStruct>();
    
    // 컴파일 타임 단언
    static_assert(std::atomic<int>::is_always_lock_free, 
                  "int must be lock-free!");
    
    return 0;
}
```

#### atomic_ref (C++20)
기존 변수를 atomic처럼 사용할 수 있게 해준다:

```cpp
#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

void demonstrate_atomic_ref() {
    int regular_int = 0;  // 일반 변수!
    
    // atomic_ref로 감싸서 atomic처럼 사용
    std::atomic_ref<int> atomic_int(regular_int);
    
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 10; ++i) {
        threads.emplace_back([&atomic_int]() {
            for (int j = 0; j < 1000; ++j) {
                atomic_int.fetch_add(1, std::memory_order_relaxed);
            }
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    std::cout << "결과: " << regular_int << "\n";  // 10000
    std::cout << "atomic_ref를 통해: " << atomic_int.load() << "\n";
}

// 실용 예제: 배열 요소를 atomic하게 업데이트
void update_array_elements() {
    int array[100] = {0};
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 10; ++i) {
        threads.emplace_back([&array, i]() {
            // 각 스레드가 다른 배열 요소 업데이트
            std::atomic_ref<int> ref(array[i]);
            
            for (int j = 0; j < 1000; ++j) {
                ref.fetch_add(1, std::memory_order_relaxed);
            }
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    for (int i = 0; i < 10; ++i) {
        std::cout << "array[" << i << "] = " << array[i] << "\n";
    }
}

int main() {
    std::cout << "=== atomic_ref 기본 사용 ===\n";
    demonstrate_atomic_ref();
    
    std::cout << "\n=== 배열 요소 업데이트 ===\n";
    update_array_elements();
    
    return 0;
}
```

#### atomic<shared_ptr> / atomic<weak_ptr> (C++20)
* C++20에서 `std::atomic`의 **부분 특수화**로 추가되어 스마트 포인터 자체를 **원자적으로 교체·관찰**할 수 있게 했다는 점이 핵심이다.  
* 제공 연산은 일반 원자와 유사하게 `load / store / exchange / compare_exchange_weak / compare_exchange_strong` 등이 포함되며, C++20의 `wait / notify_*`도 지원한다.   
* **락 프리(lock-free) 보장은 없다**는 점에 유의해야 하며, 구현에 따라 내부적으로 락을 사용할 수 있다.  
* C++11부터 제공되던 `atomic_load/atomic_store` 계열의 **비멤버 함수는 C++20 특수화 등장으로 사실상 대체**되었다.

##### `atomic<shared_ptr<T>>`의 의미
* 여러 스레드가 **동일 리소스의 소유권 포인터를 교체하거나 읽는 작업**을 데이터 레이스 없이 수행하도록 한다. 즉, “현재 공개된 객체 버전”을 **안전하게 게시(publish)·스왑**하는 용도에 적합하다.  
* `wait/notify`에서 말하는 “값의 변경”은 **저장된 원시 포인터 또는 제어 블록 포인터가 바뀐 경우**를 의미한다. 따라서 참조 대상이 바뀌면 대기 스레드가 깨어날 수 있다.  
* 참고로 `shared_ptr` 자체도 **참조 카운트 갱신은 스레드 안전**이지만, **포인터 교체의 원자성**과 **메모리 가시성 질서**는 `atomic` 특수화를 통해 보장받는다고 이해하면 된다.  

##### `atomic<weak_ptr<T>>`의 의미
* **약한 참조 자체의 게시·교체를 원자적으로** 수행하기 위한 타입이다. 여러 스레드가 최신 약한 핸들을 공유하고, 필요 시 개별 스레드에서 `lock()`으로 소유권을 승격하는 패턴에 쓰인다.  
* `weak_ptr`이 가리키는 대상 생명주기는 여전히 `shared_ptr` 소유자에 의해 결정되며, `atomic<weak_ptr>`은 **약한 핸들의 교체/관찰**을 안전하게 만들 뿐 대상 객체의 동기화를 대신해주지는 않는다.  

##### 주의점 요약
* **객체 내용물의 동기화는 별도 문제**라서, 포인터가 가리키는 객체에 대한 읽기/쓰기의 상호 배제나 순서 보장은 다른 메커니즘으로 처리해야 한다.  
* **성능 특성은 구현 의존적**이며, 필수적으로 락 프리일 필요가 없다. 실제 워크로드에서 프로파일링 후 사용을 결정하는 것이 좋다.  


```cpp
#include <atomic>
#include <memory>
#include <thread>
#include <vector>
#include <iostream>

class Resource {
private:
    int id;
public:
    Resource(int i) : id(i) {
        std::cout << "Resource " << id << " 생성\n";
    }
    
    ~Resource() {
        std::cout << "Resource " << id << " 소멸\n";
    }
    
    int get_id() const { return id; }
};

void demonstrate_atomic_shared_ptr() {
    // C++20: atomic<shared_ptr<T>>
    std::atomic<std::shared_ptr<Resource>> atomic_ptr;
    
    // 초기화
    atomic_ptr.store(std::make_shared<Resource>(1));
    
    std::vector<std::thread> threads;
    
    // 읽기 스레드들
    for (int i = 0; i < 5; ++i) {
        threads.emplace_back([&atomic_ptr, i]() {
            for (int j = 0; j < 10; ++j) {
                auto ptr = atomic_ptr.load();
                if (ptr) {
                    std::cout << "Thread " << i << " 읽음: Resource " 
                              << ptr->get_id() << "\n";
                }
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
            }
        });
    }
    
    // 쓰기 스레드
    threads.emplace_back([&atomic_ptr]() {
        for (int i = 2; i <= 5; ++i) {
            std::this_thread::sleep_for(std::chrono::milliseconds(50));
            auto new_resource = std::make_shared<Resource>(i);
            
            auto old = atomic_ptr.exchange(new_resource);
            std::cout << "교체: " << old->get_id() << " -> " << i << "\n";
        }
    });
    
    for (auto& t : threads) {
        t.join();
    }
}

// C++20 이전 방식 (레거시)
void demonstrate_legacy_shared_ptr_atomic() {
    std::shared_ptr<Resource> shared_ptr = std::make_shared<Resource>(100);
    
    // C++20 이전: 전역 함수 사용
    std::shared_ptr<Resource> loaded = std::atomic_load(&shared_ptr);
    
    auto new_ptr = std::make_shared<Resource>(200);
    std::atomic_store(&shared_ptr, new_ptr);
    
    std::shared_ptr<Resource> expected = new_ptr;
    auto newer_ptr = std::make_shared<Resource>(300);
    
    bool success = std::atomic_compare_exchange_strong(
        &shared_ptr, &expected, newer_ptr);
    
    std::cout << "CAS 성공: " << success << "\n";
}

int main() {
    std::cout << "=== C++20 atomic<shared_ptr> ===\n";
    demonstrate_atomic_shared_ptr();
    
    std::cout << "\n=== 레거시 방식 ===\n";
    demonstrate_legacy_shared_ptr_atomic();
    
    return 0;
}
```
  

## 6. 메모리 펜스 (Memory Fence)
명시적 메모리 순서 제어를 위한 펜스 함수들이다:  

```cpp
#include <atomic>
#include <thread>
#include <iostream>
#include <cassert>

// atomic_thread_fence: 컴파일러와 CPU 재배치 방지
void demonstrate_fence() {
    int data = 0;
    std::atomic<bool> ready{false};
    
    std::thread producer([&]() {
        data = 42;  // 일반 변수 쓰기
        
        // Release 펜스: 이 선 위의 모든 쓰기가 아래로 이동 불가
        std::atomic_thread_fence(std::memory_order_release);
        
        ready.store(true, std::memory_order_relaxed);
    });
    
    std::thread consumer([&]() {
        while (!ready.load(std::memory_order_relaxed)) {
            // 대기
        }
        
        // Acquire 펜스: 이 선 아래의 모든 읽기가 위로 이동 불가
        std::atomic_thread_fence(std::memory_order_acquire);
        
        assert(data == 42);  // 항상 참!
        std::cout << "Data: " << data << "\n";
    });
    
    producer.join();
    consumer.join();
}

// atomic_signal_fence: 컴파일러 재배치만 방지 (CPU 재배치는 허용)
volatile sig_atomic_t signal_received = 0;
int signal_data = 0;

void signal_handler(int) {
    signal_received = 1;
}

void demonstrate_signal_fence() {
    std::signal(SIGUSR1, signal_handler);
    
    signal_data = 100;
    
    // Signal 펜스: 시그널 핸들러와의 동기화
    std::atomic_signal_fence(std::memory_order_release);
    
    // 시그널 발생 시 signal_handler가 안전하게 signal_data 읽기 가능
}

// 실용 예제: 여러 변수의 일관성 보장
struct ComplexData {
    int x, y, z;
};

ComplexData data;
std::atomic<int> version{0};

void writer() {
    // 새 데이터 작성
    ComplexData new_data{1, 2, 3};
    
    data = new_data;  // 여러 쓰기 연산
    
    // Release 펜스로 데이터 완전성 보장
    std::atomic_thread_fence(std::memory_order_release);
    
    version.fetch_add(1, std::memory_order_relaxed);
}

void reader() {
    int current_version = version.load(std::memory_order_relaxed);
    
    // Acquire 펜스로 데이터 읽기 보호
    std::atomic_thread_fence(std::memory_order_acquire);
    
    ComplexData local_copy = data;  // 일관된 데이터 읽기
    
    std::cout << "Version " << current_version 
              << ": (" << local_copy.x << ", " 
              << local_copy.y << ", " 
              << local_copy.z << ")\n";
}

int main() {
    std::cout << "=== Thread Fence 예제 ===\n";
    demonstrate_fence();
    
    std::cout << "\n=== Complex Data 동기화 ===\n";
    std::thread t1(writer);
    std::thread t2(reader);
    
    t1.join();
    t2.join();
    
    return 0;
}
```
  


## 7. kill_dependency (최적화 힌트)

```cpp
#include <atomic>
#include <iostream>

// memory_order_consume과 함께 사용되는 최적화 힌트
std::atomic<int*> global_ptr{nullptr};

int* get_data() {
    int* ptr = global_ptr.load(std::memory_order_consume);
    
    // kill_dependency: 의존성 체인 종료
    return std::kill_dependency(ptr);
}

void demonstrate_kill_dependency() {
    int value = 42;
    global_ptr.store(&value, std::memory_order_release);
    
    int* result = get_data();
    if (result) {
        std::cout << "Value: " << *result << "\n";
    }
}
```
 
  

## 8. 고급 활용 예제

### 8.1 순차 일관성이 필요한 경우

```cpp
#include <atomic>
#include <thread>
#include <iostream>

std::atomic<bool> x{false};
std::atomic<bool> y{false};
std::atomic<int> z{0};

void write_x() {
    x.store(true, std::memory_order_seq_cst);
}

void write_y() {
    y.store(true, std::memory_order_seq_cst);
}

void read_x_then_y() {
    while (!x.load(std::memory_order_seq_cst)) {}
    
    if (y.load(std::memory_order_seq_cst)) {
        ++z;
    }
}

void read_y_then_x() {
    while (!y.load(std::memory_order_seq_cst)) {}
    
    if (x.load(std::memory_order_seq_cst)) {
        ++z;
    }
}

int main() {
    // seq_cst는 전역 순서를 보장
    // 따라서 z는 항상 1이 됨 (0이 될 수 없음)
    
    for (int i = 0; i < 1000; ++i) {
        x = false;
        y = false;
        z = 0;
        
        std::thread t1(write_x);
        std::thread t2(write_y);
        std::thread t3(read_x_then_y);
        std::thread t4(read_y_then_x);
        
        t1.join();
        t2.join();
        t3.join();
        t4.join();
        
        if (z.load() == 0) {
            std::cout << "반례 발견! (이론상 불가능)\n";
            return 1;
        }
    }
    
    std::cout << "seq_cst로 순서 보장 확인됨\n";
    return 0;
}
```

### 8.2 Peterson's Algorithm (상호 배제)

```cpp
#include <atomic>
#include <thread>
#include <iostream>
#include <vector>

class PetersonLock {
private:
    std::atomic<bool> flag[2];
    std::atomic<int> victim{0};

public:
    PetersonLock() {
        flag[0].store(false, std::memory_order_relaxed);
        flag[1].store(false, std::memory_order_relaxed);
    }

    void lock(int thread_id) {
        int other = 1 - thread_id;
        
        flag[thread_id].store(true, std::memory_order_seq_cst);
        victim.store(thread_id, std::memory_order_seq_cst);
        
        // 다른 스레드가 잠금을 원하고, 내가 victim이면 대기
        while (flag[other].load(std::memory_order_seq_cst) && 
               victim.load(std::memory_order_seq_cst) == thread_id) {
            std::this_thread::yield();
        }
    }

    void unlock(int thread_id) {
        flag[thread_id].store(false, std::memory_order_seq_cst);
    }
};

PetersonLock peterson_lock;
int shared_counter = 0;

void increment(int thread_id) {
    for (int i = 0; i < 100000; ++i) {
        peterson_lock.lock(thread_id);
        ++shared_counter;
        peterson_lock.unlock(thread_id);
    }
}

int main() {
    std::thread t0([](){ increment(0); });
    std::thread t1([](){ increment(1); });
    
    t0.join();
    t1.join();
    
    std::cout << "예상: 200000, 실제: " << shared_counter << "\n";
    
    return 0;
}
```
  


## 9. 성능 고려사항

```cpp
#include <atomic>
#include <thread>
#include <vector>
#include <chrono>
#include <iostream>

template<std::memory_order Order>
void benchmark_memory_order(const std::string& name, int iterations) {
    std::atomic<int> counter{0};
    
    auto start = std::chrono::high_resolution_clock::now();
    
    std::vector<std::thread> threads;
    for (int i = 0; i < 4; ++i) {
        threads.emplace_back([&counter, iterations]() {
            for (int j = 0; j < iterations; ++j) {
                counter.fetch_add(1, Order);
            }
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    std::cout << name << ": " << duration.count() << "ms\n";
}

int main() {
    const int iterations = 10000000;
    
    std::cout << "메모리 순서별 성능 비교:\n";
    benchmark_memory_order<std::memory_order_relaxed>("relaxed ", iterations);
    benchmark_memory_order<std::memory_order_acquire>("acquire ", iterations);
    benchmark_memory_order<std::memory_order_release>("release ", iterations);
    benchmark_memory_order<std::memory_order_acq_rel>("acq_rel ", iterations);
    benchmark_memory_order<std::memory_order_seq_cst>("seq_cst ", iterations);
    
    return 0;
}
```
  



## 10. 정리 및 API 레퍼런스

### 주요 API 요약

```cpp
// 기본 연산
T load(memory_order = seq_cst);
void store(T, memory_order = seq_cst);
T exchange(T, memory_order = seq_cst);

// Compare-and-Swap
bool compare_exchange_weak(T& expected, T desired, 
                          memory_order success, 
                          memory_order failure);
bool compare_exchange_strong(T& expected, T desired,
                             memory_order success,
                             memory_order failure);

// 산술 연산 (정수형)
T fetch_add(T, memory_order = seq_cst);
T fetch_sub(T, memory_order = seq_cst);
T fetch_max(T, memory_order = seq_cst);  // C++20
T fetch_min(T, memory_order = seq_cst);  // C++20

// 비트 연산 (정수형)
T fetch_and(T, memory_order = seq_cst);
T fetch_or(T, memory_order = seq_cst);
T fetch_xor(T, memory_order = seq_cst);

// 대기/통지 (C++20)
void wait(T old, memory_order = seq_cst);
void notify_one();
void notify_all();

// atomic_flag 전용
bool test_and_set(memory_order = seq_cst);
void clear(memory_order = seq_cst);
bool test(memory_order = seq_cst);  // C++20

// 유틸리티
bool is_lock_free() const;
static constexpr bool is_always_lock_free;  // C++17
```

### 메모리 순서 사용 가이드

```
┌─────────────────────────────────────────────────────┐
│ 사용 사례별 메모리 순서 선택                         │
├─────────────────────────────────────────────────────┤
│                                                     │
│ 단순 카운터        → relaxed                        │
│ 플래그 체크        → relaxed (읽기), release (쓰기) │
│ 생산자-소비자      → acquire/release                │
│ 복잡한 동기화      → seq_cst                        │
│ 성능 크리티컬      → 프로파일링 후 결정             │
│                                                     │
└─────────────────────────────────────────────────────┘
```

#### `memory_order_seq_cst`의 의미

* 모든 원자 연산이 **전역적으로 일관된 순서**로 수행됨을 보장한다.
* 즉, 여러 스레드에서 수행된 atomic 연산들이 한 줄로 나열된 것처럼 동작한다.
* 프로그램이 직관적으로 이해되며, 디버깅과 검증이 쉽다.

**예시**

```cpp
std::atomic<int> a{0}, b{0};

void thread1() {
    a.store(1, std::memory_order_seq_cst);
    int x = b.load(std::memory_order_seq_cst);
}

void thread2() {
    b.store(1, std::memory_order_seq_cst);
    int y = a.load(std::memory_order_seq_cst);
}
```

이 경우, 두 스레드가 서로의 `store`보다 앞선 `load`를 관찰하는 일(즉, `x == 0 && y == 0`)은 절대 발생하지 않는다.


#### 다른 메모리 오더의 용도

`seq_cst`보다 성능이 중요한 상황에서는 필요에 따라 다음을 고려할 수 있다.

| 메모리 오더                 | 특징                                    | 사용 예                            |
| ---------------------- | ------------------------------------- | ------------------------------- |
| `memory_order_relaxed` | 순서 제약 없음, 단일 변수에 대한 원자성만 보장           | 단순 카운터, 통계 수집                   |
| `memory_order_release` | 이후 연산이 다른 스레드에서 관측되기 전에 저장됨           | 생산자 스레드의 `store`                |
| `memory_order_acquire` | 이전 스레드의 `store(release)` 결과를 읽을 때 동기화 | 소비자 스레드의 `load`                 |
| `memory_order_acq_rel` | `acquire` + `release` 동시 효과           | `fetch_add` 등 read-modify-write |
| `memory_order_seq_cst` | 가장 강력하고 직관적인 순서 보장                    | 일반적인 기본 선택                      |


#### 실무적 권장 순서

1. **기본값으로 `seq_cst` 사용**
   → 코드가 단순하고 오류 가능성이 적다.
2. **성능 병목이 확인되면**
   → 해당 구간만 `acquire/release` 또는 `relaxed`로 미세 조정한다.
3. **무조건 처음부터 최적화하지 않는다**
   → 메모리 오더 관련 버그는 디버깅이 매우 어렵다.

  
#### 요약

* **처음에는 항상 `std::memory_order_seq_cst`로 시작한다.**
* **성능 분석을 통해 병목이 명확할 때만 완화된 오더를 선택한다.**
* **`relaxed`는 데이터 일관성이 필요 없는 경우에만 신중히 사용한다.**

즉, “기본적으로는 `memory_order_seq_cst`가 안전하고 권장되는 선택”이다.
